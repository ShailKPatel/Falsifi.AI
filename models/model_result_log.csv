id,Model_Name,Pipeline,Feature_Extractor,Loss,Description,Accuracy,F1,Recall,Precision,Best_Loss,Justification
1,SiameseCNN,ContrastiveLoss,CNN(3 conv + 2 fc),ContrastiveLoss,Two-branch CNN extracts embeddings and contrastive loss enforces distance for signature verification,0.6051,0.5676,0.9517,0.7111,0.184023,Basic Siamese CNN baseline chosen to establish reference performance and enable comparison with more complex models
2,TripletCNN-Reduced10p,TripletPipeline (10% data),CNN(3 conv + 2 fc),TripletMarginLoss,Triplet CNN trained on 10% subsampled CEDAR triplets with margin-based embedding separation,0.4894,0.4894,1.0000,0.6571,0.0000,Dataset reduced to 10% for computational efficiency; training-only run establishes feasibility of triplet embedding on small-scale data
3,SigNet+AugmentationFast,SiameseCNN with Advanced Augmentation,CNN(3 conv + 2 fc),ContrastiveLoss,SigNet-style Siamese CNN with random rotation; elastic distortions; Gaussian noise; AMP mixed-precision and cuDNN autotune for efficiency,0.0723,0.0617,0.0630,0.0624,0.002007,Designed to improve robustness on small signature data by simulating handwriting variability while accelerating training with GPU optimizations
4,ResNet18Siamese,TransferLearning Siamese,ResNet18 pretrained + FC(128),ContrastiveLoss,Siamese with ResNet18 backbone frozen then fine tuned with ImageNet normalization and light affine plus flip augmentation producing 128D L2 embeddings,0.4309,0.4339,0.4227,0.4457,0.000006,Leverages transfer learning for richer features on small CEDAR and two stage training improves stability and performance
5,ResNet50Siamese,TransferLearning Siamese,ResNet50 pretrained + FC(128),ContrastiveLoss,Siamese with deeper ResNet50 backbone fine tuned after freezing early layers & producing 128D L2 normalized embeddings,0.6553,0.6120,0.8080,0.6964,0.000010,Deeper backbone selected to capture finer handwriting features and test whether added capacity improves verification over ResNet18 baseline
